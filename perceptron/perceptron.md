# Percepron
퍼셉트론은 다수의 입력 -> 하나의 출력이 특징이다.  
각 입력에는 __가중치__(W, weight)가 곱해져서 보내진다.  
ex) 입력 x1, x2 그리고 가중치 w1, w2
```
x1*w1+x2*w2 = t 
```
가중치가 클수록, 해당 입력 신호는 중요함을 의미한다 (결과값에 영향을 더 주니).  

## AND, NAND 그리고 OR 게이트
세가지 논리 게이트는 입력값이 4가지 경우로 제한되므로  
결국은 가중치 값이 결과를 좌우한다.   
가중치를 적절하게 조절한다면 손쉽게 구현 가능.(해당 디렉토리 logic.py 참고)
ex) AND 게이트  
입력값 모두가 1인 경우만 결과가 1이다. 
```
0.4x1 + 0.7x2 > 1.0 
```
둘다 1인 경우만 만족. 

## 학습이란?
위에서 본 논리 게이트의 경우 퍼셉트론의 구조 자체는 모두 동일하다.  
달라지는 것은 가중치의 값.  
사람은 입력을 보면서 적절한 가중치를 찾는다.  
동일하게, 컴퓨터가 자동으로 적절한 가중치를 찾아가는 작업이 바로 __학습__이다.  

## 편향(bias)이란?
위의 퍼셉트론 구현에서는 식이 임계값을 넘는지의 여부를 결정함.  
```
	0 (w1x1+w2x2 <= t)
y = 
	1 (w1x1+w2x2 > t)
```
여기서, t를 -b로 치환하고 이항하면,  
```
	0 (w1x1+w2x2+b <= 0)
y = 
	1 (w1x1+w2x2+b > 0)
```
여기서의 b를 bias 즉 편향이라고 하며,  
이는 뉴런이 얼마나 쉽게 활성화되는지를 결정. 
편향이 클수록 좀만 더해지면 활성화. 
## 퍼셉트론의 한계
퍼셉트론은 영역을 직선으로 나눈다.  
AND, NAND 그리고 OR은 모든 경우를 직선 하나로 구분이 가능하지만,  
XOR은 곡선이 아니고서야 구분할 수 없다.  
이런 경우, 퍼셉트론을 여러층 쌓으면 구현할 수 있다(Multi-layer perceptron).


